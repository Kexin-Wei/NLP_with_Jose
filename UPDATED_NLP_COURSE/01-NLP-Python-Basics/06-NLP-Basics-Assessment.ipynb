{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Basics Assessment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "    doc = nlp(f.read())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. How many tokens are contained in the file?**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "len(doc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4833"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "sents = [sent for sent in doc.sents]\n",
    "len(sents)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sents[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sents[1]:\n",
    "    print(token.text,token.pos_,token.dep_,token.lemma_)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A DET det a\n",
      "man NOUN nsubj man\n",
      "stood VERB ROOT stand\n",
      "upon ADP prep upon\n",
      "a DET det a\n",
      "railroad NOUN compound railroad\n",
      "bridge NOUN pobj bridge\n",
      "in ADP prep in\n",
      "northern ADJ amod northern\n",
      "Alabama PROPN pobj alabama\n",
      ", PUNCT punct ,\n",
      "looking VERB advcl look\n",
      "down PART prt down\n",
      "\n",
      " SPACE  \n",
      "\n",
      "into ADP prep into\n",
      "the DET det the\n",
      "swift ADJ amod swift\n",
      "water NOUN pobj water\n",
      "twenty NUM nummod twenty\n",
      "feet NOUN npadvmod foot\n",
      "below ADV advmod below\n",
      ". PUNCT punct .\n",
      "  SPACE   \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in sents[1]:\n",
    "    print(f'{token.text:<12}{token.pos_:<6}{token.dep_:<8}{token.lemma_:<12}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A           DET   det     a           \n",
      "man         NOUN  nsubj   man         \n",
      "stood       VERB  ROOT    stand       \n",
      "upon        ADP   prep    upon        \n",
      "a           DET   det     a           \n",
      "railroad    NOUN  compoundrailroad    \n",
      "bridge      NOUN  pobj    bridge      \n",
      "in          ADP   prep    in          \n",
      "northern    ADJ   amod    northern    \n",
      "Alabama     PROPN pobj    alabama     \n",
      ",           PUNCT punct   ,           \n",
      "looking     VERB  advcl   look        \n",
      "down        PART  prt     down        \n",
      "\n",
      "           SPACE         \n",
      "           \n",
      "into        ADP   prep    into        \n",
      "the         DET   det     the         \n",
      "swift       ADJ   amod    swift       \n",
      "water       NOUN  pobj    water       \n",
      "twenty      NUM   nummod  twenty      \n",
      "feet        NOUN  npadvmodfoot        \n",
      "below       ADV   advmod  below       \n",
      ".           PUNCT punct   .           \n",
      "            SPACE                     \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "pattern = [{\"LOWER\":\"swimming\"},{\"IS_SPACE\":True,\"OP\":\"*\"},{\"LOWER\":\"vigorously\"}]\n",
    "\n",
    "matcher.add(\"Swimming\",None,pattern)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3607, 3610)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**7. Print the text surrounding each found match**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print(doc[found_matches[0][1]-9:found_matches[0][2]+9])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print(doc[found_matches[1][1]-7:found_matches[1][2]+ 5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "for match in found_matches:\n",
    "    for sent in sents:\n",
    "        if match[1] < sent.end:\n",
    "            print(sent)\n",
    "            break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n",
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Great Job!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('nlp_jose': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "e75e4640d5ff591db314380ebf58a481dcfa583d18c102045d637b9bda5a1165"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}